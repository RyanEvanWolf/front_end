#!/usr/bin/env python

import math
import time

import pickle

import cv2
import numpy as np
import rospy
from cv_bridge import CvBridge
from front_end.motion import *
from front_end.simulation import *
from sensor_msgs.msg import CameraInfo, Image
from tf.transformations import quaternion_from_euler, quaternion_matrix

import argparse
rospy.init_node('motionSimulation')
cvb=CvBridge()


parser =argparse.ArgumentParser()
parser.add_argument("worldFolder")
parser.add_argument("--root_dir",default="/media/ryan/EXTRA/output/Simulation",type=str)
args,unknown=parser.parse_known_args()
d=simDirectory(args.root_dir)
f=open(args.root_dir+"/Nister.p", 'r')
NisterSettings=pickle.load(f)
f.close()

NisterExtractor=nisterExtract("/media/ryan/EXTRA/output/Simulation",NisterSettings)

worldFilesSet=os.listdir(args.root_dir+"/"+args.worldFolder)
for Hpickle in worldFilesSet:
    f=open(args.root_dir+"/"+args.worldFolder+"/"+Hpickle,"r")
    data=pickle.load(f)
    f.close()  
    print(getMotion(data["H"]),"ideal")
    for curve in data["Curves"]:
        ###get each Curve ID and pack it into a list
        currentPoints=[]
        previousPoints=[]
        currentLandmarks=[]
        previousLandmarks=[]
        curveID=str(len(curve))

        for pointIndex in curve:
            currentPoints.append([data["Points"][pointIndex]["Lb"][0,0],data["Points"][pointIndex]["Lb"][1,0]])
            currentLandmarks.append(data["Points"][pointIndex]["Xb"])
            previousPoints.append([data["Points"][pointIndex]["La"][0,0],data["Points"][pointIndex]["La"][1,0]])
            previousLandmarks.append(data["Points"][pointIndex]["Xa"])
            

        r=NisterExtractor.extractScaledMotion(currentPoints,currentLandmarks,previousPoints,previousLandmarks,True)
#             f=open(self.output+"/"+inputFolder+"/"+Hpickle,"w")
#             pickle.dump(HResults,f)
#             f.close()
        print(getMotion(decomposeTransform(r["H"])),"measured")
        print(compareMotion(data["H"],decomposeTransform(r["H"])),"percent")
    print("---")

# class nisterExtract:
#     def __init__(self,rootDir,extractConfig):
#         self.root=rootDir
#         self.output=rootDir+"/Nister"
#         self.extract=extractConfig
#     def extractMotion(self,inputFolder):
#         worldFilesSet=os.listdir(self.root+"/"+inputFolder)
#         print("Loaded From "+self.root+"/"+inputFolder)
#         for Hpickle in worldFilesSet:
#             f=open(self.root+"/"+inputFolder+"/"+Hpickle,"r")
#             data=pickle.load(f)
#             f.close()
#             print(getMotion(data["H"]))
#             HResults={}
#             for curve in data["Curves"]:
#                 curveID=str(len(curve))
#                 HResults[curveID]={}
#                 simulationPoints=[]
#                 for pointIndex in curve:
#                     simulationPoints.append(data["Points"][pointIndex])
#                     newPts=np.zeros((len(simulationPoints),2),dtype=np.float64)
#                     oldPts=np.zeros((len(simulationPoints),2),dtype=np.float64)
#                 for j in range(0,len(simulationPoints)):
#                     newPts[j,0]=simulationPoints[j]["Lb"][0]
#                     newPts[j,1]=simulationPoints[j]["Lb"][1]
#                     oldPts[j,0]=simulationPoints[j]["La"][0]
#                     oldPts[j,1]=simulationPoints[j]["La"][1]
#                 E,mask=cv2.findEssentialMat(newPts,oldPts,self.extract["f"],self.extract["pp"])
#                                             #,prob=self.extract["probability"],threshold=self.extract["threshold"])#,threshold=1)    #
#                 nInliers,R,T,matchMask=cv2.recoverPose(E,newPts,oldPts,self.extract["k"],mask)
#                 averageScale=np.zeros((3,3),dtype=np.float64)
#                 countedIn=0
#                 for index in range(0,len(simulationPoints)):
#                     i=simulationPoints[index]
#                     if(matchMask[index,0]==255):
#                         scale=(i["Xa"][0:3,0]-R.dot(i["Xb"][0:3,0])).reshape(3,1).dot(np.transpose(T.reshape(3,1))).dot(np.linalg.pinv(T.dot(np.transpose(T))))
#                         averageScale+=scale 
#                         countedIn+=1
#                 averageScale=averageScale/nInliers
#                 T=averageScale.dot(T)  
#                 original=createHomog(R,T)
#                 HResults[curveID]["H"]=np.linalg.inv(original)
#                 print(getMotion(HResults[curveID]["H"]))
#                 HResults[curveID]["Motion"]=getMotion(HResults[curveID]["H"]) 
#                 HResults[curveID]["inlierMask"]=matchMask
#                 HResults[curveID]["nInlier"]=nInliers
#                 HResults[curveID]["inlierRatio"]=nInliers/float(len(simulationPoints))
#                 HResults[curveID]["E"]=E
#                 HResults[curveID]["MotionError"]=compareMotion(HResults[curveID]["H"],data["H"])
#                 HResults[curveID]["CurveID"]=len(simulationPoints)
#                 HResults[curveID]["PointResults"]=[]
#                 #####get reprojection results
#                 for index in range(0,len(simulationPoints)):
#                     i=simulationPoints[index]
#                     if(matchMask[index,0]==255):
#                         HResults[curveID]["PointResults"].append(self.getLandmarkReprojection(i,HResults[curveID]["H"]) )
#             f=open(self.output+"/"+inputFolder+"/"+Hpickle,"w")
#             pickle.dump(HResults,f)
#             f.close()
#             print("----")    
